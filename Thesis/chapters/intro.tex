\chapter{Introduction}
In recent years, quantum algorithms have garnered significant attention for their potential to disrupt traditional cryptographic systems. The security of many important communication channels, including the internet as we know it, is ensured by classical cryptographic protocols, particularly those based on the hardness of certain mathematical problems. With the rise of quantum technology, new algorithms have been found that exploit quantum mechanical principles, such as superposition and entanglement, to solve these problems exponentially faster than classical algorithms. Still, the implementation of quantum algorithms for cryptographic purposes continues to be largely theoretical. A quantum computer capable of breaking the most-used algorithms today is yet to be constructed, as there are many practical limitations to doing so%\cite{dtu}
. Thus, practical quantum computers (with thousands of qubits and low error rates) remain an area of active research; there is considerable anticipation surrounding the eventual realization of the theoretical promises associated with quantum computing. As we move into the post-quantum era, it will become increasingly important to assess our cryptographic protocols in light of the most recent developments in the field, in order to maintain and protect critical infrastructure and assets.

Brute-force searches are a technique that may be employed to break cryptographic systems that use so-called \emph{symmetric} keys\footnote{Symmetric-key algorithms use the same keys for encryption and decryption \cite{symmetric}, as opposed to \emph{asymmetric} algorithms, which use separate encryption and decryption keys. This project will focus on the former.}. Performing such a search involves quite simply checking every single possible key option until the right key is found, an inordinately time-consuming process if the key space is large enough. Our current protocols ensure security against these searches by having key lengths large enough that it is considered computationally infeasible for a classical computer to identify one in any reasonable amount of time. A closer look at the popular symmetric-key algorithm \emph{Advanced Encryption Standard} (AES) \cite{aes} exemplifies this: It exists in versions that use key sizes of 128, 192 and 256 bits, resulting in search spaces of $2^{128}$, $2^{192}$ and $2^{256}$ possible keys respectively.

%A relevant quantum algorithm here is \emph{Grover's algorithm}\cite{introQCbook}, in which a procedure is given for a quantum computer to solve the brute-force searching problem, thereby potentially threatening the security of AES. Its asymptotic runtime (meaning the approximate number of operations needed for the algorithm to run as a function of the decryption key length $N$) is $\mathcal{O}(\sqrt{N})$, compared to the classical approach with $\mathcal{O}(N)$ \cite{introQCbook}. 
A relevant quantum algorithm here is \emph{Grover's algorithm} \cite{dewolf2023quantumcomputinglecturenotes}, in which a procedure is given for a quantum computer to do a brute-force search much faster than classical computers, thereby potentially threatening the security of AES. Its asymptotic runtime (meaning the approximate number of operations needed for the algorithm to run as a function of the decryption key length $N$) is $\mathcal{O}(\sqrt{N})$, compared to the classical approach with $\mathcal{O}(N)$ \cite{introQCbook}.
However, finding the exact runtime is not as straightforward as the asymptotic estimates, which do not consider constant values, nor do they take into account what kind of parallelization may be possible. Analyzing the true cost of using Grover's algorithm in reality is a nontrivial problem that warrants further exploration, which constitutes the core of this project.

%What do we need for a quantum computer to work?\\
Building a quantum machine in practice is no easy feat. The root of the issue is that quantum information is extremely fragile. The qubits that store information are unstable and very vulnerable to noise that changes the value the qubit holds. We therefore wish to construct circuits of multiple qubits that work together to protect the information from errors, such that they form a single logical qubit that can have its errors located and corrected, making them more stable. This approach, though useful, will often require large numbers of qubits, which poses an engineering challenge to keep them all as stable as possible, facilitate connections between them, and perform computations on the logical qubits, rather than on the physical qubits individually.

Samuel Jacques\supervisors{Do I need more context about him and his credibility?} considers this in his 2024 analysis of Grover's algorithm as a quantum attack on AES \cite{jaques2024ches_presentation}, where he suggests that due to the error correction models and gate sets currently in widespread use, a physical implementation of Grover's algorithm will never see the light of day on anything resembling current quantum architectures (or maybe ever). This project uses his argumentation as a starting point for further analysis, aiming to tackle some of the assumptions he makes and explore alternatives to some of the runtime bottlenecks he identifies.

% % What am I going to do?\\
% As a starting point for this project, I aim to recreate the work of Samuel Jacques, as laid out in his 2024 talk. Jacques takes a very pessimistic view on the potential use cases for Grover's algorithm to break AES, by which I mean he believes these use cases are entirely nonexistent. His argument relies on a series of assumptions for this to be the case. In the beginning stages of this project, I will tackle these assumptions case by case and see if it changes the conclusion at all. Along the way, we will run into a number of topics that I am not really familiar with, and we will have to acquire some knowledge to say if the arguments presented by Jacques still hold in these alternative cases.

\supervisorsinline{I am planning to add a little more info towards the end here about my experiments and method as soon as I make a final decision on the direction I want to take this. It will probably include discussions of other error correcting codes like \emph{BB codes} or \emph{tile codes}. As in, ``since Jacques' argumentation bases itself so much on our continued usage of the surface code, what does his analysis look like under the assumption of a better error correcting code?''}

